{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invasive Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd data/train\n",
    "%mkdir 0\n",
    "%mkdir 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "with open('../train_labels.csv') as csvfile:\n",
    "    labels = csv.reader(csvfile, delimiter='\\n')\n",
    "    for row in labels:\n",
    "        columns = row[0].split(',')\n",
    "        if columns[0] != 'name':\n",
    "            if columns[1] == '0':\n",
    "                os.rename(columns[0] + '.jpg', '0/{}.jpg'.format(columns[0]))\n",
    "            else:\n",
    "                os.rename(columns[0] + '.jpg', '1/{}.jpg'.format(columns[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir ../valid\n",
    "%mkdir ../valid/0\n",
    "%mkdir ../valid/1\n",
    "%cd 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "np.random.shuffle(g)\n",
    "for i in range(math.floor(len(g) / 10)):\n",
    "    os.rename(g[i], '../../valid/0/' + g[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd ../1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "np.random.shuffle(g)\n",
    "for i in range(math.floor(len(g) / 10)):\n",
    "    os.rename(g[i], '../../valid/1/' + g[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/usr/local/lib/python3.5/dist-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6021 on context None\n",
      "Preallocating 3633/4037 Mb (0.900000) on cuda1\n",
      "Mapped name None to device cuda1: GeForce GTX 970 (0000:02:00.0)\n"
     ]
    }
   ],
   "source": [
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = vgg.get_batches(path + 'train', batch_size=batch_size)\n",
    "valid_batches = vgg.get_batches(path + 'valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(path + 'finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.fit(batches, math.floor(2067/batch_size), epochs=20, \n",
    "        validation_batches=valid_batches, \n",
    "        validation_steps=math.floor(228/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.save_weights(path + 'finetune1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Finetune earlier layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg.model.layers[12:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.fit(batches, math.floor(2067/batch_size), epochs=20, \n",
    "        validation_batches=valid_batches, \n",
    "        validation_steps=math.floor(228/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg.model.layers[10:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.fit(batches, math.floor(2067/batch_size), epochs=5, \n",
    "        validation_batches=valid_batches, \n",
    "        validation_steps=math.floor(228/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg.model.layers[8:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.fit(batches, math.floor(2067/batch_size), epochs=10, \n",
    "        validation_batches=valid_batches, \n",
    "        validation_steps=math.floor(228/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg.model.layers[4:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.fit(batches, math.floor(2067/batch_size), epochs=10, \n",
    "        validation_batches=valid_batches, \n",
    "        validation_steps=math.floor(228/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg.model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.fit(batches, math.floor(2067/batch_size), epochs=10, \n",
    "        validation_batches=valid_batches, \n",
    "        validation_steps=math.floor(228/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.save_weights(path + 'finetune1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2067 images belonging to 2 classes.\n",
      "Found 228 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(horizontal_flip=True, zoom_range=0.2, shear_range=0.2, \n",
    "                         width_shift_range=0.2, \n",
    "                         height_shift_range=0.2,)\n",
    "batches = vgg.get_batches(path + 'train', batch_size=batch_size, gen=gen)\n",
    "valid_batches = vgg.get_batches(path + 'valid', batch_size=batch_size, gen=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 39s - loss: 0.2432 - acc: 0.8955 - val_loss: 0.2820 - val_acc: 0.8705\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 34s - loss: 0.2311 - acc: 0.9127 - val_loss: 0.3013 - val_acc: 0.8827\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 34s - loss: 0.2329 - acc: 0.8922 - val_loss: 0.2336 - val_acc: 0.9031\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 34s - loss: 0.2420 - acc: 0.8966 - val_loss: 0.2159 - val_acc: 0.9082\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 34s - loss: 0.2559 - acc: 0.8903 - val_loss: 0.2293 - val_acc: 0.9133\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 34s - loss: 0.2522 - acc: 0.8961 - val_loss: 0.2739 - val_acc: 0.8776\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 34s - loss: 0.2418 - acc: 0.8950 - val_loss: 0.2218 - val_acc: 0.9031\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 34s - loss: 0.2347 - acc: 0.8976 - val_loss: 0.2257 - val_acc: 0.9133\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 34s - loss: 0.2231 - acc: 0.9031 - val_loss: 0.2588 - val_acc: 0.9184\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 34s - loss: 0.2424 - acc: 0.8953 - val_loss: 0.2563 - val_acc: 0.8929\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 34s - loss: 0.2307 - acc: 0.9064 - val_loss: 0.2354 - val_acc: 0.9082\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 34s - loss: 0.2378 - acc: 0.8961 - val_loss: 0.2781 - val_acc: 0.8776\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 34s - loss: 0.2502 - acc: 0.9007 - val_loss: 0.2678 - val_acc: 0.9031\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 34s - loss: 0.2073 - acc: 0.9092 - val_loss: 0.2084 - val_acc: 0.9235\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 34s - loss: 0.2526 - acc: 0.8851 - val_loss: 0.2505 - val_acc: 0.8520\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 34s - loss: 0.2275 - acc: 0.8979 - val_loss: 0.2373 - val_acc: 0.9031\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 34s - loss: 0.2492 - acc: 0.8908 - val_loss: 0.2022 - val_acc: 0.9133\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 34s - loss: 0.2243 - acc: 0.8984 - val_loss: 0.2362 - val_acc: 0.9031\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 34s - loss: 0.2321 - acc: 0.9022 - val_loss: 0.2775 - val_acc: 0.8776\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 34s - loss: 0.2382 - acc: 0.8978 - val_loss: 0.3001 - val_acc: 0.8622\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 34s - loss: 0.2335 - acc: 0.8986 - val_loss: 0.2340 - val_acc: 0.8776\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 34s - loss: 0.2369 - acc: 0.8961 - val_loss: 0.2391 - val_acc: 0.8827\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 34s - loss: 0.2439 - acc: 0.8978 - val_loss: 0.2163 - val_acc: 0.9082\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 34s - loss: 0.2337 - acc: 0.9051 - val_loss: 0.2056 - val_acc: 0.9082\n",
      "Epoch 25/30\n"
     ]
    }
   ],
   "source": [
    "vgg.fit(batches, math.floor(2067/batch_size), epochs=30,\n",
    "        validation_batches=valid_batches, \n",
    "        validation_steps=math.floor(228/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
